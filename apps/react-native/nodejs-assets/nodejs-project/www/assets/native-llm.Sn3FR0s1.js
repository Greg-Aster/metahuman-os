import{A as n,_ as r}from"./api-config.BAZ_dc_Y.js";let a=null;async function i(){if(a)return a;if(!n()){const{NativeLLMWeb:e}=await r(async()=>{const{NativeLLMWeb:t}=await import("./native-llm-web.Dc5PBOVh.js");return{NativeLLMWeb:t}},[]);return a=new e,a}const{registerPlugin:l}=await r(async()=>{const{registerPlugin:e}=await import("./index.CXATIzgh.js");return{registerPlugin:e}},[]);return a=l("NativeLLM",{web:()=>r(()=>import("./native-llm-web.Dc5PBOVh.js"),[]).then(e=>new e.NativeLLMWeb)}),a}class o{checkAvailability(){if(!n())throw new Error("NativeLLM is only available on native platforms")}async isModelLoaded(){return n()?(await i()).isModelLoaded():{loaded:!1}}async loadModel(e){return this.checkAvailability(),(await i()).loadModel(e)}async unloadModel(){return this.checkAvailability(),(await i()).unloadModel()}async generate(e){return this.checkAvailability(),(await i()).generate(e)}async chat(e){return this.checkAvailability(),(await i()).chat(e)}async listModels(){return n()?(await i()).listModels():{models:[]}}async downloadModel(e){return this.checkAvailability(),(await i()).downloadModel(e)}async getStatus(){return n()?(await i()).getStatus():{inferring:!1,modelLoaded:!1,memoryUsageMB:0,cpuUsagePercent:0}}async cancelInference(){return n()?(await i()).cancelInference():{cancelled:!1}}async addListener(e,t){if(!n())return{remove:()=>{}};const s=await i();return s.addListener(e,t)}}const c=new o;export{c as NativeLLM};
