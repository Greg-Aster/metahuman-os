[2025-12-03T21:02:34.203Z] === Starting new training run ===
[2025-12-03T21:02:34.203Z] Date: 2025-12-03
[2025-12-03T21:02:34.203Z] Run label: 2025-12-03-205450-df1cfd
[2025-12-03T21:02:34.203Z] Work directory: /home/greggles/metahuman/metahuman-runs/greggles/2025-12-03/2025-12-03-205450-df1cfd
[2025-12-03T21:02:34.204Z] RUNPOD_NO_GATEWAY=1 set; skipping gateway schema probes.
[2025-12-03T21:02:34.204Z] RUNPOD_DIRECT_SSH_USER=root; will prefer this user for direct SSH.
[2025-12-03T21:02:34.204Z] Using RUNPOD_TEMPLATE_ID=6r5jlk3b89
[2025-12-03T21:02:34.204Z] LoRA mode: Using NVIDIA GeForce RTX 5090
[2025-12-03T21:02:34.204Z] Selected GPU type: NVIDIA GeForce RTX 5090
[2025-12-03T21:02:34.204Z] Attempting to deploy pod on COMMUNITY cloud...
[2025-12-03T21:02:35.142Z] Pod created successfully on COMMUNITY cloud. Pod ID: s0smex6qxnrq43
[2025-12-03T21:02:35.143Z] Waiting for pod to become RUNNING...
[2025-12-03T21:02:35.144Z] Waiting for pod ssh gateway... (Attempt 1/120)
[2025-12-03T21:02:40.686Z] Waiting for pod ssh gateway... (Attempt 2/120)
[2025-12-03T21:02:46.176Z] Waiting for pod ssh gateway... (Attempt 3/120)
[2025-12-03T21:02:51.654Z] Waiting for pod ssh gateway... (Attempt 4/120)
[2025-12-03T21:02:57.134Z] Waiting for pod ssh gateway... (Attempt 5/120)
[2025-12-03T21:03:02.626Z] Waiting for pod ssh gateway... (Attempt 6/120)
[2025-12-03T21:03:08.286Z] Waiting for pod ssh gateway... (Attempt 7/120)
[2025-12-03T21:03:13.901Z] Waiting for pod ssh gateway... (Attempt 8/120)
[2025-12-03T21:03:19.448Z] Waiting for pod ssh gateway... (Attempt 9/120)
[2025-12-03T21:03:24.980Z] Waiting for pod ssh gateway... (Attempt 10/120)
[2025-12-03T21:03:30.608Z] Waiting for pod ssh gateway... (Attempt 11/120)
[2025-12-03T21:03:36.138Z] Waiting for pod ssh gateway... (Attempt 12/120)
[2025-12-03T21:03:41.667Z] Waiting for pod ssh gateway... (Attempt 13/120)
[2025-12-03T21:03:47.197Z] Waiting for pod ssh gateway... (Attempt 14/120)
[2025-12-03T21:03:52.727Z] Waiting for pod ssh gateway... (Attempt 15/120)
[2025-12-03T21:03:58.257Z] Waiting for pod ssh gateway... (Attempt 16/120)
[2025-12-03T21:04:03.812Z] Waiting for pod ssh gateway... (Attempt 17/120)
[2025-12-03T21:04:09.417Z] Waiting for pod ssh gateway... (Attempt 18/120)
[2025-12-03T21:04:14.904Z] Waiting for pod ssh gateway... (Attempt 19/120)
[2025-12-03T21:04:20.502Z] Waiting for pod ssh gateway... (Attempt 20/120)
[2025-12-03T21:04:26.109Z] Waiting for pod ssh gateway... (Attempt 21/120)
[2025-12-03T21:04:31.641Z] Waiting for pod ssh gateway... (Attempt 22/120)
[2025-12-03T21:04:37.156Z] Waiting for pod ssh gateway... (Attempt 23/120)
[2025-12-03T21:04:42.678Z] Waiting for pod ssh gateway... (Attempt 24/120)
[2025-12-03T21:04:48.227Z] Waiting for pod ssh gateway... (Attempt 25/120)
[2025-12-03T21:04:53.841Z] Waiting for pod ssh gateway... (Attempt 26/120)
[2025-12-03T21:04:59.391Z] Waiting for pod ssh gateway... (Attempt 27/120)
[2025-12-03T21:05:05.038Z] Waiting for pod ssh gateway... (Attempt 28/120)
[2025-12-03T21:05:10.634Z] Waiting for pod ssh gateway... (Attempt 29/120)
[2025-12-03T21:05:16.159Z] Waiting for pod ssh gateway... (Attempt 30/120)
[2025-12-03T21:05:21.712Z] Waiting for pod ssh gateway... (Attempt 31/120)
[2025-12-03T21:05:27.189Z] Waiting for pod ssh gateway... (Attempt 32/120)
[2025-12-03T21:05:32.648Z] Waiting for pod ssh gateway... (Attempt 33/120)
[2025-12-03T21:05:38.203Z] Waiting for pod ssh gateway... (Attempt 34/120)
[2025-12-03T21:05:43.730Z] Waiting for pod ssh gateway... (Attempt 35/120)
[2025-12-03T21:05:49.362Z] Waiting for pod ssh gateway... (Attempt 36/120)
[2025-12-03T21:05:54.932Z] Waiting for pod ssh gateway... (Attempt 37/120)
[2025-12-03T21:06:00.424Z] Waiting for pod ssh gateway... (Attempt 38/120)
[2025-12-03T21:06:05.950Z] Waiting for pod ssh gateway... (Attempt 39/120)
[2025-12-03T21:06:11.402Z] Waiting for pod ssh gateway... (Attempt 40/120)
[2025-12-03T21:06:16.910Z] Waiting for pod ssh gateway... (Attempt 41/120)
[2025-12-03T21:06:22.407Z] Waiting for pod ssh gateway... (Attempt 42/120)
[2025-12-03T21:06:27.963Z] Waiting for pod ssh gateway... (Attempt 43/120)
[2025-12-03T21:06:33.455Z] Waiting for pod ssh gateway... (Attempt 44/120)
[2025-12-03T21:06:38.927Z] Waiting for pod ssh gateway... (Attempt 45/120)
[2025-12-03T21:06:44.448Z] Waiting for pod ssh gateway... (Attempt 46/120)
[2025-12-03T21:06:49.917Z] Waiting for pod ssh gateway... (Attempt 47/120)
[2025-12-03T21:06:55.412Z] Waiting for pod ssh gateway... (Attempt 48/120)
[2025-12-03T21:07:00.918Z] Waiting for pod ssh gateway... (Attempt 49/120)
[2025-12-03T21:07:06.336Z] Waiting for pod ssh gateway... (Attempt 50/120)
[2025-12-03T21:07:11.900Z] Waiting for pod ssh gateway... (Attempt 51/120)
[2025-12-03T21:07:17.450Z] Waiting for pod ssh gateway... (Attempt 52/120)
[2025-12-03T21:07:22.958Z] Waiting for pod ssh gateway... (Attempt 53/120)
[2025-12-03T21:07:28.589Z] Waiting for pod ssh gateway... (Attempt 54/120)
[2025-12-03T21:07:29.125Z] runtime.ports: [{"ip":"100.65.25.61","isIpPublic":false,"privatePort":19123,"publicPort":60004,"type":"http"},{"ip":"87.197.110.78","isIpPublic":true,"privatePort":22,"publicPort":40168,"type":"tcp"},{"ip":"87.197.110.78","isIpPublic":true,"privatePort":22,"publicPort":40169,"type":"udp"}]
[2025-12-03T21:07:29.125Z] Public port mapping detected and NO_GATEWAY=1; proceeding without gateway discovery.
[2025-12-03T21:07:29.126Z] Using default SSH key path: /home/greggles/.ssh/id_ed25519
[2025-12-03T21:07:29.126Z] Key path candidate: /home/greggles/.ssh/id_ed25519
[2025-12-03T21:07:29.126Z] SSH probe candidates: root
[2025-12-03T21:07:31.965Z] Direct SSH handshake succeeded as root@87.197.110.78:40168 (attempt 1)
[2025-12-03T21:07:31.966Z] Wrote fresh connection.json for this pod: /home/greggles/metahuman/metahuman-runs/greggles/2025-12-03/2025-12-03-205450-df1cfd/connection.json
[2025-12-03T21:07:31.966Z] Using direct SSH mode: root@87.197.110.78:40168
[2025-12-03T21:07:31.967Z] Checking for Python, pip, and workspace setup
[2025-12-03T21:07:34.927Z] Environment check passed: Python 3.12.3
pip 25.2 from /usr/local/lib/python3.12/dist-packages/pip (python 3.12)
input
train_unsloth.py
unsloth-venv
ENV_READY

[2025-12-03T21:07:34.927Z] Uploading curated training files via base64-over-ssh (samples: 368)...
[2025-12-03T21:07:37.722Z] Directory creation result: total 4
drwxr-xr-x 5 root root   97 Dec  3 21:06 .
drwxr-xr-x 1 root root   86 Dec  3 21:06 ..
drwxr-xr-x 3 root root   25 Dec  3 21:06 .cache
drwxr-xr-x 2 root root   10 Oct 27 16:03 input
-rw-rw-r-- 1 root root 3177 Oct 27 02:08 train_unsloth.py
drwxr-xr-x 6 root root  115 Dec  3 21:06 unsloth-venv

[2025-12-03T21:07:37.723Z] Uploading unsloth_dataset.jsonl to /workspace/input/unsloth_dataset.jsonl (attempt 1/3)...
[2025-12-03T21:07:41.922Z] Upload of unsloth_dataset.jsonl successful.
[2025-12-03T21:07:41.923Z] Uploading config.json to /workspace/input/config.json (attempt 1/3)...
[2025-12-03T21:07:45.067Z] Upload of config.json successful.
[2025-12-03T21:07:45.069Z] Uploading core.json to /workspace/input/persona.json (attempt 1/3)...
[2025-12-03T21:07:48.040Z] Upload of core.json successful.
[2025-12-03T21:07:48.042Z] Uploaded persona data for training context
[2025-12-03T21:07:48.042Z] LoRA training mode detected
[2025-12-03T21:07:48.042Z] Uploading training script from: /home/greggles/metahuman/docker/runpod-trainer/train_unsloth.py
[2025-12-03T21:07:48.043Z] Uploading train_unsloth.py to /workspace/train_unsloth.py (attempt 1/3)...
[2025-12-03T21:07:51.012Z] Upload of train_unsloth.py successful.
[2025-12-03T21:07:53.790Z] Training script verification: 492 /workspace/train_unsloth.py
-rw-rw-r-- 1 root root 21K Dec  3 21:07 /workspace/train_unsloth.py
[2025-12-03T21:07:59.526Z] Upload verification: 7ceea09989c342137e20919a3605dfe556b0ea36e4586e016fa361d59853a5f4  /workspace/input/config.json
[2025-12-03T21:07:59.526Z] Executing remote training script: train_unsloth.py
[2025-12-03T21:24:56.507Z] Training exit code: 1
[2025-12-03T21:24:56.508Z] Full training output saved to: /home/greggles/metahuman/metahuman-runs/greggles/2025-12-03/2025-12-03-205450-df1cfd/training_output.txt
[2025-12-03T21:24:56.508Z] Training stderr (last 2000 chars): : rcvd ext data 103
debug2: channel 0: rcvd ext data 104
Unsloth: Merging weights into 16bit: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:32<00:00,  5.29s/it]Unsloth: Merging weights into 16bit: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:32<00:00,  5.43s/it]
debug2: channel 0: written 207 to efd 6
debug2: channel 0: rcvd ext data 491
[train_unsloth] ERROR: Unsloth: GGUF conversion failed: Unsloth: Quantization failed for qwen3-14b.Q4_K_M.gguf
You might have to compile llama.cpp yourself, then run this again.
You do not need to close this Python program. Run the following commands in a new terminal:
You must run this in the same folder as you're saving your model.
git clone --recursive https://github.com/ggerganov/llama.cpp
cd llama.cpp && make clean && make all -j
Once that's done, redo the quantization.
Error: {e}
debug2: channel 0: written 491 to efd 6
debug2: channel 0: rcvd ext data 151
[W1203 21:24:55.923293532 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
debug2: channel 0: written 151 to efd 6
debug2: channel 0: rcvd eof
debug2: channel 0: output open -> drain
debug2: channel 0: obuf empty
debug2: chan_shutdown_write: channel 0: (i0 o1 sock -1 wfd 5 efd 6 [write])
debug2: channel 0: output drain -> closed
debug1: client_input_channel_req: channel 0 rtype exit-status reply 0
debug1: client_input_channel_req: channel 0 rtype eow@openssh.com reply 0
debug2: channel 0: rcvd eow
debug2: chan_shutdown_read: channel 0: (i0 o3 sock -1 wfd 4 efd 6 [write])
debug2: channel 0: input open -> closed
debug2: channel 0: rcvd close
debug2: channel 0: almost dead
debug2: channel 0: gc: notify user
debug2: channel 0: gc: user detached
debug2: channel 0: send close
debug2: channel 0: is dead
debug2: channel 0: garbage collecting
debug1: channel 0: free: client-session, nchannels 1
Transferred: sent 4252, received 31944 bytes, in 1014.4 seconds
Bytes per second: sent 4.2, received 31.5
debug1: Exit status 1

[2025-12-03T21:24:56.508Z] Training stdout (last 2000 chars): pter weights...
[21:15:46] ðŸ“Š SAVE_ADAPTER (100%) - âœ… Adapter saved
[21:15:46] â–¶ï¸  GGUF_MERGE - ðŸ”„ Merging adapter with base model...
[21:15:46] â–¶ï¸  GGUF_MERGE - Converting to GGUF Q4_K_M format (this may take 5-10 minutes)
[21:15:46] â–¶ï¸  GGUF_DEPS - Installing required packages: gguf, mistral_common
[21:15:47] â–¶ï¸  GGUF_DEPS - Packages ready via uv pip
Unsloth: Merging model weights to 16-bit format...
Found HuggingFace hub cache directory: /workspace/.cache/huggingface/hub
Checking cache directory for required files...
Cache check failed: model-00001-of-00006.safetensors not found in local cache.
Not all required files found in cache. Will proceed with downloading.
Checking cache directory for required files...
Cache check failed: tokenizer.model not found in local cache.
Not all required files found in cache. Will proceed with downloading.
Note: tokenizer.model not found (this is OK for non-SentencePiece models)
Unsloth: Merge process complete. Saved to `/workspace/merged_gguf_output`
Unsloth: Converting to GGUF format...
==((====))==  Unsloth: Conversion from HF to GGUF information
   \\   /|    [0] Installing llama.cpp might take 3 minutes.
O^O/ \_/ \    [1] Converting HF to GGUF bf16 might take 3 minutes.
\        /    [2] Converting GGUF bf16 to ['q4_k_m'] might take 10 minutes each.
 "-____-"     In total, you will have to wait at least 16 minutes.

Unsloth: Installing llama.cpp. This might take 3 minutes...
Unsloth: Updating system package directories
Unsloth: All required system packages already installed!
Unsloth: Install llama.cpp and building - please wait 1 to 3 minutes
Unsloth: Cloning llama.cpp repository
Unsloth: Install GGUF and other packages
Unsloth: Successfully installed llama.cpp!
Unsloth: Preparing converter script...
Unsloth: [1] Converting model into bf16 GGUF format.
This might take 3 minutes...
Unsloth: Initial conversion completed! Files: ['qwen3-14b.BF16.gguf']
Unsloth: [2] Converting GGUF bf16 into q4_k_m. This might take 10 minutes...

[2025-12-03T21:24:56.508Z] Remote training script failed.
[2025-12-03T21:24:56.508Z] Downloading merged GGUF and adapter artifacts...
[2025-12-03T21:24:56.508Z] Skipping GGUF download due to training failure.
[2025-12-03T21:24:56.508Z] Starting SCP download: scp -r -P 40168 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -i /home/greggles/.ssh/id_ed25519 root@87.197.110.78:/workspace/output/adapter /home/greggles/metahuman/metahuman-runs/greggles/2025-12-03/2025-12-03-205450-df1cfd/temp_adapter_download
[2025-12-03T21:27:14.999Z] SCP download successful for /workspace/output/adapter
[2025-12-03T21:27:15.000Z] An error occurred: EXDEV: cross-device link not permitted, rename '/home/greggles/metahuman/metahuman-runs/greggles/2025-12-03/2025-12-03-205450-df1cfd/temp_adapter_download/adapter/README.md' -> '/media/greggles/STACK/metahuman-profiles/greggles/out/adapters/2025-12-03/2025-12-03-205450-df1cfd/adapter/README.md'
[2025-12-03T21:27:15.001Z] Terminating pod s0smex6qxnrq43...
[2025-12-03T21:27:15.437Z] Pod termination request sent successfully.
